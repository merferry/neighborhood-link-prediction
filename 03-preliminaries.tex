In an undirected graph $G(V, E)$ with sets of vertices $V$ and edges $E$, link prediction aims to identify missing or future edges from the set $U - E$, where $U$ contains all possible $|V|(|V|-1)/2$ edges in the graph \cite{zhou2021progresses}. Link prediction, thus, is akin to finding a needle in a haystack, as the correct edges need to be identified within a vast set of incorrect ones \cite{garcia2014link, wang2014link}. Garcia et. al \cite{garcia2014link} observe that this ratio goes from $1:11k$ in their best case to $1:27M$ in the worst case. Further, larger graphs more likely to be incomplete. These challenges make the study of link prediction crucial.

Link prediction often relies on similarity metrics between node pairs, reflecting the likelihood of missing or future links \cite{wang2014link, arrar2023comprehensive}. The idea is grounded in the tendency for users to connect with similar individuals. More similarity thus suggests a higher probability of a future link. A ranked list of potential links based on similarity scores can then be used to predict the top-$k$ links are most likely to appear (on were missing) \cite{wang2014link}. Similarity measures are commonly categorized into local, quasi-local, and global measures. Local / neighborhood-based metrics, like Common Neighbours (CN), are calculated based on neighborhood information within a path distance of two. Global indices use network-wide information, while quasi-local indices combine both for distances up to two \cite{arrar2023comprehensive}.

As brought up earlier, despite typically having lower prediction accuracy than machine learning based approaches, similarity-based link prediction methods remain relevant due to the need for simple algorithms in handling large graphs \cite{garcia2014link}. Further, they are highly cost-effective, interpretable, and offer competitive prediction quality with low time and space complexity \cite{zhou2021progresses, barbieri2014follow}.




\subsection{Neighborhood-based Similarity Metrics}

We now discuss nine commonly used local / neighborhood-based similarity metrics for link prediction.


\subsubsection{Common Neighbors (CN)}

This metric, shown in Equation \ref{eq:cn}, counts the shared neighbors between two vertices, $a$ and $b$, in a graph \cite{newman2001clustering}. However, its lack of normalization may pose challenges when comparing node pairs with different degrees of connectivity.

\begin{equation}
\label{eq:cn}
  CN(a, b) = |\Gamma_a \cap \Gamma_b|
\end{equation}


\subsubsection{Jaccard Coefficient (JC)}

The Jaccard Coefficient (JC) \cite{jaccard1901etude} is a popular similarity measure\ignore{in network analysis and link prediction}. It offers a normalized assessment of similarity between nodes based on their neighborhoods. Defined by Equation \ref{eq:jc}, JC assigns higher values to node pairs with a greater proportion of common neighbors relative to their total neighbors.

\begin{equation}
\label{eq:jc}
  JC(a, b) = \frac{|\Gamma_a \cap \Gamma_b|}{|\Gamma_a \cup \Gamma_b|}
\end{equation}


\subsubsection{S{\o}rensen Index (SI)}

S{\o}rensen Index (SI) \cite{sorensen1948method}, also known as S{\o}rensen–Dice coefficient, is another similarity metric commonly applied in network analysis and link prediction. This metric, defined by Equation \ref{eq:si}, extends beyond solely accounting for the size of common neighbors and introduces the idea that nodes with lower degrees are more likely to form links.

\begin{equation}
\label{eq:si}
  SI(a, b) = \frac{|\Gamma_a \cap \Gamma_b|}{|\Gamma_a| + |\Gamma_b|}
\end{equation}


\subsubsection{Salton Cosine similarity (SC)}

The Salton Cosine similarity (SC) \cite{salton1973specification} essentially measures the cosine of the angle between the vectors representing the neighborhoods of nodes $a$ and $b$, as given in Equation \ref{eq:sc}. Similar to other metrics, a higher SC value indicates a greater similarity in the neighborhood structures of the nodes, implying a higher likelihood of a link between them.

\begin{equation}
\label{eq:sc}
  SC(a, b) = \frac{|\Gamma_a \cap \Gamma_b|}{\sqrt{|\Gamma_a| \cdot |\Gamma_b|}}
\end{equation}


\subsubsection{Hub Promoted (HP)}

The HP \cite{liben2003link} metric, defined by Equation \ref{eq:hp}, assesses topological overlap between two nodes in a graph. It is particularly influenced by the lower degree of nodes, and can be valuable in scenarios where the involvement of lower-degree nodes is considered important in understanding network connectivity.

\begin{equation}
\label{eq:hp}
  HP(a, b) = \frac{|\Gamma_a \cap \Gamma_b|}{min(|\Gamma_a|, |\Gamma_b|)}
\end{equation}


\subsubsection{Hub Depressed (HD)}

In contrast to the HP metric, the Hub Depressed (HD) score \cite{zhou2009predicting} is determined by the higher degrees of nodes, as illustrated by Equation \ref{eq:hd}. It can be particularly useful in cases where the influence of highly connected nodes on network structure is of interest.

\begin{equation}
\label{eq:hd}
  HD(a, b) = \frac{|\Gamma_a \cap \Gamma_b|}{max(|\Gamma_a|, |\Gamma_b|)}
\end{equation}


\subsubsection{Leicht-Holme-Nerman (LHN)}

The Leicht-Holme-Nerman (LHN) score \cite{leicht2006vertex} is a similarity metric that assigns high similarity to node pairs that exhibit a greater number of common neighbors than would be expected by random chance. One may use Equation \ref{eq:lhn} to compute the LHN score between two nodes $a$ and $b$ in a graph.

\begin{equation}
\label{eq:lhn}
  LHN(a, b) = \frac{|\Gamma_a \cap \Gamma_b|}{|\Gamma_a| \cdot |\Gamma_b|}
\end{equation}


\subsubsection{Adamic-Adar coefficient (AA)}

AA \cite{adamic2003friends} is a popular measure designed to capture the notion that connections to common neighbors with fewer links are more informative and indicative of similarity between nodes in a network. The formula in Equation \ref{eq:aa} assigns weights inversely proportional to the logarithm of the number of neighbors, reducing sensitivity to highly connected nodes.\ignore{AA highlights that links to less common neighbors provide more discriminative information about node similarity.}

\begin{equation}
\label{eq:aa}
  AA(a, b) = \sum_{c\ \in\ \Gamma_a \cup \Gamma_b} \frac{1}{\log{|\Gamma_c|}}
\end{equation}


\subsubsection{Resource Allocation (RA)}

The RA metric \cite{zhou2010solving} is based on the concept of heat diffusion in a network, emphasizing that heavily connected nodes may not play a critical role in facilitating resource flow between other nodes. Unlike AA, RA penalizes high-degree common neighbors more heavily. The score between nodes $a$ and $b$ is determined by Equation \ref{eq:ra}.

\begin{equation}
\label{eq:ra}
  RA(a, b) = \sum_{c\ \in\ \Gamma_a \cup \Gamma_b} \frac{1}{|\Gamma_c|}
\end{equation}

Note that the CN, AA, and RA metrics lack normalization, and thus only convey ranking information \cite{wang2014link}. In practical applications, one should choose the right metric based on the network's characteristics --- there is no universally dominating metric \cite{zhou2021progresses, ghasemian2020stacking, wang2014link, liben2003link}.




\subsection{Measuring Prediction Quality}

There are a number of metrics used to evaluate the performance of a link prediction model \cite{arrar2023comprehensive}. Performance evaluation metrics can be roughly divided into two categories: threshold-dependent, and threshold-independent metrics \cite{zhou2021progresses}. Precision and recall are the two most widely used metrics in the former category, while Area Under the ROC Curve (AUC), where ROC stands for Receiver operating characteristic, is the most widely used in the later category. To test the algorithm’s accuracy, the observed link, $E$, is divided into two parts: the training set $E^T$ is treated as known information, while the probe set $E^P$ is used for algorithm evaluation, and no information in $E^P$ is allowed to be used for prediction. The majority of known studies applied ‘‘random division’’, namely $E^P$ is randomly drawn from $E$ \cite{zhou2021progresses}.

\ignore{Current link prediction experimental results are usually very low in evaluation metrics values \cite{wang2014link}.}


\subsubsection{Precision}

Precision is a metric used to evaluate the performance of a link prediction model. It measures the proportion of correctly classified positive links (i.e. links that actually exist) among all classified positive links \cite{arrar2023comprehensive}.

Precision is defined as the ratio of relevant items selected to the number of items selected \cite{zhou2021progresses}, i.e., it measures the proportion of correctly classified positive links (i.e. links that actually exist) among all classified positive links \cite{arrar2023comprehensive}. In other words, if we take the top-$L$ links as the predicted ones; among which $L_r$ links are correctly predicted; then, the Precision equals $L_r/L$ \cite{zhou2021progresses}. Equation \ref{eq:precision} gives the formula for computing precision.

\begin{equation}
\label{eq:precision}
  \text{Precision} = \frac{TP}{TP + FP}
\end{equation}


\subsubsection{Recall}

Recall is defined as the ratio of relevant items selected to the total number of relevant items (say $L_r = |E^P|$) \cite{zhou2021progresses}, or the ratio of correctly classified positive links to the total number of positive links \cite{arrar2023comprehensive}. The formula for calculating recall in given in Equation \ref{eq:recall}. A widely adopted way is setting $L = |E^P|$, at which precision = recall \cite{lu2011link, liben2003link, zhou2021progresses}. Although $|E^P|$ is generally unknown, an experiential and reasonable setting is  $|E^P| = 0.1 |E|$ because $10\%$ of links in the probe set are usually enough for us to get statistical solid results while the removal of $10\%$ of links will probably not destroy the structural features of the target network \cite{lu2015toward}.

\begin{equation}
\label{eq:recall}
  \text{Recall} = \frac{TP}{TP + FN}
\end{equation}


\subsubsection{F1 Score}

F1 Score is a measure of the balance between precision and recall \cite{arrar2023comprehensive}. It can calculated as the harmonic mean of percision and recall, as shown in Equation \ref{eq:f1score}.

\begin{equation}
\label{eq:f1score}
  \text{F1 score} = 2 * \frac{\text{Precision} * \text{Recall}}{\text{Precision} + \text{Recall}}
\end{equation}


\subsubsection{Accuracy}

Accuracy is a metric that indicates the percentage of correctly classified links by a link prediction model \cite{arrar2023comprehensive}. It can be calculated using Equation \ref{eq:accuracy}.

\begin{equation}
\label{eq:accuracy}
  \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
\end{equation}


\subsubsection{Area Under the ROC Curve (AUC)}

Area Under the Receiver (AUC) \cite{hanley1982meaning} is the area under the receiver operating characteristic curve (ROC) is a measure of the prediction algorithm's ability to distinguish between positive and negative links \cite{arrar2023comprehensive}. A higher AUC value indicates a more efficient algorithm compared to random choice \cite{mumin2022efficient}. However, AUC is inadequate to evaluate the early retrieval performance which is critical in real applications \cite{zhou2021progresses}. AUC will give misleadingly overhigh score to algorithms that can successfully rank many negatives in the bottom while this ability is less significant in imbalanced learning \cite{yang2015evaluating, lichtnwalter2012link}.


\ignore{How do you explore the neighbors of each node, and compute intersection? What is a super naive way to do the above?}
