Consider a social network $G(V,E)$ at a particular time $t$, where $V$ and $E$ are sets of nodes and links, respectively \cite{wang2014link}. The link prediction aims to predict new links or deleted links between nodes for a future time $t$ ($t > t$), or missing links or unobserved links, in the current network \cite{wang2014link}. This problem can be explained by a simple social network about five persons in Figure 6, in which solid links indicate interactions already existing at time $t$, and dashed links indicate links that have newly appeared during the interval time $[t, t]$. At time $t$, Alice and Bob are friends, Alice and Nick are also friends. At time $t$, maybe Alice has introduced Bob to Nick, they become friends too. Analogously, Nick and Amy would become friends at time $t$. The goal of the link prediction problem here is to predict the appearance of newly added friendship between persons \cite{wang2014link}.

To solve the link prediction problem, it needs to determine the formation or dissolution possibilities of links between all node pairs. Usually, such possibilities can be measured by similarities or relative ranks between node pairs. We use a generic framework to illustrate the link prediction solution as shown in Figure 7. For an initial social network, there are two ways to predict the link evolution: similarity-based approaches and learning-based approaches. Here we take predicting the new/missing/unobserved links as examples. A similarity-based approach is to compute the similarities on non-connected pairs of nodes in a social network, namely, it is based on measures for analyzing the proximity of nodes. Every potential node pair (x, y) would be assigned a score, where higher score means higher probability that x and y will be linked in the future, and vice versa. Then a ranked list in decreasing order of scores is obtained and links at the top of the list are most likely to appear. A learning-based approach is treating the link prediction problem as a binary classification task \cite{al2006link}. Therefore, some typical machine learning models such as classifiers and probabilistic models can be used for solving this problem. Each non-connected pair of nodes corresponds to an instance with features describing nodes and the class label. If there is a potential link connecting a pair of nodes, this pair is labeled as positive, otherwise it is negative. For the learning-based approaches, the features consist of two parts: one is the similarity features from the similarity-based approaches, another is the features derived from the social network, such as the textual information of attributes and domain knowledge. Link prediction for deleting/disappearing links can be solved analogously \cite{wang2014link}.

Computing the similarity between a node pair is an intuitive solution for link prediction. It is based on the simple idea: the more similar the pair is, the more likely a link between them, and vice versa. This is consistent with the fact that users tend to create relationships with people who are similar in education, religions, interests and locations. It can be measured by the similarity, in which each nonconnected pair of nodes (x, y) is assigned a score signifying similarity between x and y. A high score indicates high probability that x and y will be linked in the future, while a low score also indicates high probability that x and y will not be linked. Therefore, using the rank of similarity scores, we can predict the appearing or disappearing links in the future or unseen links in current networks \cite{wang2014link}.






\subsection{Link prediction}

The size of graphs originated from the web, social networks or biological relations forces us to use very simple algorithms if those graphs are to be computed in acceptable time \cite{garcia2014link}.

The smallest graph we use has 89,000 nodes and the largest 17 million. Their ratio of positive:negative edges goes from 1:11,000 in the best case (Wordnet) to 1:27 million in the worst case (Wikipedia). This huge imbalance makes LP a needle in a haystack problem, where we are trying to find a tiny set of correct edges within a huge set of incorrect ones. This inconvenient setting must not be considered as something abnormal or to be fixed. Instead we must accept it as an intrinsic property of large and sparse graphs and try to work around it \cite{garcia2014link}.

Overcoming imbalance. Link prediction problem always suffers from extreme imbalance, namely, the number of links known to be present is often much less than the number of links known to be absent. This imbalance hampers the effectiveness of many link prediction methods \cite{wang2014link}.

Current link prediction experimental results are usually in very low evaluation metrics values \cite{wang2014link}.

A few works discuss the prediction of links that will disappear in the future \cite{almansoori2012link}.

Similarity is a measure used to evaluate the level of similarity or connection between two nodes in a network \cite{arrar2023comprehensive}. It is frequently used to predict the likelihood of a link forming between two nodes that are not currently connected in the network \cite{arrar2023comprehensive}. The most similarity measures between nodes, used in link prediction studies, are local, quasi-local, and global indices \cite{arrar2023comprehensive}.

Local indices, such as Common Neighbours \cite{newman2001clustering}, Salton Index \cite{salton1973specification}, Jaccard Index \cite{jaccard1901etude}, Sorensen Index \cite{sorensen1948method}, Hub Promoted Index \cite{liben2003link}, Preferential Attachment Index \cite{barabasi1999emergence}, Adamic–Adar Index \cite{adamic2003friends}, and Resource Allocation Index \cite{zhou2010solving}, calculate scores based on the neighborhood information of nodes with a path distance less than two \cite{arrar2023comprehensive}.

Global indices use information from the entire network to calculate scores with a path distance greater than two \cite{arrar2023comprehensive}.

Quasi-local indices combine the advantages of local and global indices and calculate scores for nodes with a path distance of no more than two \cite{arrar2023comprehensive}.




\subsection{Precision}

Precision is a metric used to evaluate the performance of a link prediction model. It measures the proportion of correctly classified positive links (i.e. links that actually exist) among all classified positive links \cite{arrar2023comprehensive}.

\begin{equation}
\label{eq:precision}
  \text{Precision} = \frac{TP}{TP + FP}
\end{equation}

Recall is the ratio of correctly classified positive links to the total number of positive links \cite{arrar2023comprehensive}.

\begin{equation}
\label{eq:recall}
  \text{Recall} = \frac{TP}{TP + FN}
\end{equation}

F1 Score is a measure of the balance between precision and recall \cite{arrar2023comprehensive}.

\begin{equation}
\label{eq:f1score}
  \text{F1 score} = 2 * \frac{\text{Precision} * \text{Recall}}{\text{Precision} + \text{Recall}}
\end{equation}

Accuracy is a metric that indicates the percentage of correctly classified links by a link prediction model \cite{arrar2023comprehensive}.

\begin{equation}
\label{eq:accuracy}
  \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
\end{equation}

Area Under the Receiver (AUC) \cite{hanley1982meaning} is the area under the receiver operating characteristic curve (ROC) is a measure of the model’s ability to distinguish between positive and negative links \cite{arrar2023comprehensive}. A higher AUC value indicates a more efficient algorithm compared to random choice \cite{mumin2022efficient}. 


In social network analysis, the similarity measure based on the number of common neighbors is often used as a first-order heuristic function to predict potential friendship relations. It has been shown to achieve satisfactory performance \cite{arrar2023comprehensive}.

However, this heuristic may not be effective when it is applied to protein–protein interaction networks. In these types of networks, two proteins sharing many common neighbors may still have a low probability of interacting, making this heuristic a non-reliable predictor in this context \cite{arrar2023comprehensive}.



\subsection{Jaccard Coefficient (JC)}

The Jaccard Coefficient (JC) \cite{jaccard1901etude} is a similarity measure commonly used in network analysis and link prediction. It provides a normalized assessment of the similarity between two nodes in a graph, in terms of their neighborhoods. JC is defined such that it assigns higher values to pairs of nodes that share a greater proportion of common neighbors relative to their total number of neighbors, as given in Equation \ref{eq:jc}.

\begin{equation}
\label{eq:jc}
  JC(i, j) = \frac{|\Gamma_i \cap \Gamma_j|}{|\Gamma_i \cup \Gamma_j|}
\end{equation}




\subsection{S{\o}rensen Index (SI)}

The S{\o}rensen Index (SI) \cite{sorensen1948method}, also known as the S{\o}rensen–Dice coefficient, is another similarity metric commonly applied in network analysis and link prediction. This metric, defined by Equation \ref{eq:si}, extends beyond solely accounting for the size of common neighbors and introduces the idea that nodes with lower degrees are more likely to form links.

\begin{equation}
\label{eq:si}
  SI(i, j) = \frac{|\Gamma_i \cap \Gamma_j|}{|\Gamma_i| + |\Gamma_j|}
\end{equation}




\subsection{Salton Cosine similarity (SC)}

The Salton Cosine similarity (SC) \cite{salton1973specification} is a frequently used cosine metric in the context of measuring similarity between two nodes in a graph. It essentially measures the cosine of the angle between the vectors representing the neighborhoods of nodes $i$ and $j$, as given in Equation \ref{eq:sc}. Similar to other metrics, a higher SC value indicates a greater similarity in the neighborhood structures of the nodes, implying a higher likelihood of a link between them.

\begin{equation}
\label{eq:sc}
  SC(i, j) = \frac{|\Gamma_i \cap \Gamma_j|}{\sqrt{|\Gamma_i| \cdot |\Gamma_j|}}
\end{equation}




\subsection{Hub Promoted (HP)}

The Hub Promoted (HP) score \cite{liben2003link} is a metric that assesses the topological overlap between two nodes, denoted as $i$ and $j$, in a graph. It is defined by the formula given in Equation \ref{eq:hp}. The HP score is particularly influenced by the lower degree of nodes, and can be valuable in scenarios where the involvement of lower-degree nodes is considered important in understanding network connectivity.

\begin{equation}
\label{eq:hp}
  HP(i, j) = \frac{|\Gamma_i \cap \Gamma_j|}{min(|\Gamma_i|, |\Gamma_j|)}
\end{equation}




\subsection{Hub Depressed (HD)}

In contrast to the HP score, the Hub Depressed (HD) score \cite{zhou2009predicting} is determined by the higher degrees of nodes. It can be particularly useful in cases where the influence of highly connected nodes on network structure is of interest. The HD score between two nodes $i$ and $j$ in the graph is defined as per Equation \ref{eq:hd}.

\begin{equation}
\label{eq:hd}
  HD(i, j) = \frac{|\Gamma_i \cap \Gamma_j|}{max(|\Gamma_i|, |\Gamma_j|)}
\end{equation}




\subsection{Leicht-Holme-Nerman (LHN)}

The Leicht-Holme-Nerman (LHN) score \cite{leicht2006vertex} is a similarity metric that assigns high similarity to node pairs that exhibit a greater number of common neighbors than would be expected by random chance. One may use Equation \ref{eq:lhn} to compute the LHN score between two nodes $i$ and $j$ in a graph.

\begin{equation}
\label{eq:lhn}
  LHN(i, j) = \frac{|\Gamma_i \cap \Gamma_j|}{|\Gamma_i| \cdot |\Gamma_j|}
\end{equation}




\subsection{Adamic-Adar coefficient (AA)}

The Adamic-Adar coefficient (AA) \cite{adamic2003friends} is a measure designed to capture the notion that connections to common neighbors with fewer links are more informative and indicative of similarity between nodes in a network. The formula for this metric is given by Equation \ref{eq:aa}, where $\Gamma_i$ and $\Gamma_j$ represent the neighbors of node $i$ and $j$. The weight assigned to each common neighbor is inversely proportional to the logarithm of the number of neighbors that neighbor has. This logarithmic weighting downplays the influence of common neighbors with very high degrees, making the metric less sensitive to connections with nodes that are overly connected in the network. The AA metric metric thus captures the idea that connections to less common neighbors provide more discriminative information about the similarity between nodes.

\begin{equation}
\label{eq:aa}
  AA(i, j) = \sum_{k\ \in\ \Gamma_i \cup \Gamma_j} \frac{1}{\log{|\Gamma_k|}}
\end{equation}




\subsection{Resource Allocation (RA)}

The Resource Allocation (RA) \cite{zhou2010solving} metric was originally motivated by the concept of resource allocation, or heat diffusion, across a user-object network. It reflects the intuition that heavily connected nodes may already have abundant connections and may not play as critical a role in facilitating resource flow between two other nodes. Unlike AA, high-degree common neighbors are penalized more heavily in the RA metric. The formula for RA score between two nodes $i$ and $j$ is given by Equation \ref{eq:ra}.

\begin{equation}
\label{eq:ra}
  RA(i, j) = \sum_{k\ \in\ \Gamma_i \cup \Gamma_j} \frac{1}{|\Gamma_k|}
\end{equation}

CN, AA, PA and RA, are not normalized, that means the similarities under these metrics only have the ranking meanings \cite{wang2014link}.

Finally, we should draw attention to the fact that, although there are many existing neighbor-based metrics, in practical applications, one should choose the right metrics according to the characteristics of social networks, because many experiment evaluation results have shown that there is no absolutely dominating metric for different datasets \cite{liben2003link, wang2014link}.
