In an undirected graph $G(V, E)$ with sets of vertices $V$ and edges $E$, link prediction aims to identify missing or future edges from the set $U - E$, where $U$ contains all possible $|V|(|V|-1)/2$ edges in the graph \cite{zhou2021progresses}. Link prediction, thus, is akin to finding a needle in a haystack, as the correct edges need to be identified within a vast set of incorrect ones \cite{garcia2014link, wang2014link}. Garcia et. al \cite{garcia2014link} observe that this ratio goes from $1:11k$ in their best case to $1:27M$ in the worst case. Further, larger graphs more likely to be incomplete. These challenges make the study of link prediction crucial.

Link prediction often relies on similarity metrics between node pairs, reflecting the likelihood of missing or future links \cite{wang2014link, arrar2023comprehensive}. The idea is grounded in the tendency for users to connect with similar individuals. More similarity thus suggests a higher probability of a future link. A ranked list of potential links based on similarity scores can then be used to predict the top-$k$ links are most likely to appear (on were missing) \cite{wang2014link}. Similarity measures are commonly categorized into local, quasi-local, and global measures. Local / neighborhood-based metrics, like Common Neighbours (CN), are calculated based on neighborhood information within a path distance of two. Global indices use network-wide information, while quasi-local indices combine both for distances up to two \cite{arrar2023comprehensive}.

As brought up earlier, despite typically having lower prediction accuracy than machine learning based approaches, similarity-based link prediction methods remain relevant due to the need for simple algorithms in handling large graphs \cite{garcia2014link}. Further, they are highly cost-effective, interpretable, and offer competitive prediction quality with low time and space complexity \cite{zhou2021progresses, barbieri2014follow}.




\subsection{Neighborhood-based Similarity Metrics}
\label{sec:metrics}

We now discuss nine commonly used local / neighborhood-based similarity metrics for link prediction.


\subsubsection{Common Neighbors (CN)}

This metric, shown in Equation \ref{eq:cn}, counts the shared neighbors between two vertices, $a$ and $c$, in a graph \cite{newman2001clustering}. However, its lack of normalization may pose challenges when comparing node pairs with different degrees of connectivity.

\begin{equation}
\label{eq:cn}
  CN(a, c) = |\Gamma_a \cap \Gamma_c|
\end{equation}


\subsubsection{Jaccard Coefficient (JC)}

The Jaccard Coefficient (JC) \cite{jaccard1901etude} is a popular similarity measure\ignore{in network analysis and link prediction}. It offers a normalized assessment of similarity between nodes based on their neighborhoods. Defined by Equation \ref{eq:jc}, JC assigns higher values to node pairs with a greater proportion of common neighbors relative to their total neighbors.

\begin{equation}
\label{eq:jc}
  JC(a, c) = \frac{|\Gamma_a \cap \Gamma_c|}{|\Gamma_a \cup \Gamma_c|}
\end{equation}


\subsubsection{S{\o}rensen Index (SI)}

S{\o}rensen Index (SI) \cite{sorensen1948method}, also known as S{\o}rensenâ€“Dice coefficient, is another similarity metric commonly applied in network analysis and link prediction. This metric, defined by Equation \ref{eq:si}, extends beyond solely accounting for the size of common neighbors and introduces the idea that nodes with lower degrees are more likely to form links.

\begin{equation}
\label{eq:si}
  SI(a, c) = \frac{|\Gamma_a \cap \Gamma_c|}{|\Gamma_a| + |\Gamma_c|}
\end{equation}


\subsubsection{Salton Cosine similarity (SC)}

The Salton Cosine similarity (SC) \cite{salton1973specification} essentially measures the cosine of the angle between the vectors representing the neighborhoods of nodes $a$ and $c$, as given in Equation \ref{eq:sc}. Similar to other metrics, a higher SC value indicates a greater similarity in the neighborhood structures of the nodes, implying a higher likelihood of a link between them.

\begin{equation}
\label{eq:sc}
  SC(a, c) = \frac{|\Gamma_a \cap \Gamma_c|}{\sqrt{|\Gamma_a| \cdot |\Gamma_c|}}
\end{equation}


\subsubsection{Hub Promoted (HP)}

The HP \cite{liben2003link} metric, defined by Equation \ref{eq:hp}, assesses topological overlap between two nodes in a graph. It is particularly influenced by the lower degree of nodes, and can be valuable in scenarios where the involvement of lower-degree nodes is considered important in understanding network connectivity.

\begin{equation}
\label{eq:hp}
  HP(a, c) = \frac{|\Gamma_a \cap \Gamma_c|}{min(|\Gamma_a|, |\Gamma_c|)}
\end{equation}


\subsubsection{Hub Depressed (HD)}

In contrast to the HP metric, the Hub Depressed (HD) score \cite{zhou2009predicting} is determined by the higher degrees of nodes, as illustrated by Equation \ref{eq:hd}. It can be particularly useful in cases where the influence of highly connected nodes on network structure is of interest.

\begin{equation}
\label{eq:hd}
  HD(a, c) = \frac{|\Gamma_a \cap \Gamma_c|}{max(|\Gamma_a|, |\Gamma_c|)}
\end{equation}


\subsubsection{Leicht-Holme-Nerman (LHN)}

The Leicht-Holme-Nerman (LHN) score \cite{leicht2006vertex} is a similarity metric that assigns high similarity to node pairs that exhibit a greater number of common neighbors than would be expected by random chance. One may use Equation \ref{eq:lhn} to compute the LHN score between two nodes $a$ and $b$ in a graph.

\begin{equation}
\label{eq:lhn}
  LHN(a, c) = \frac{|\Gamma_a \cap \Gamma_c|}{|\Gamma_a| \cdot |\Gamma_c|}
\end{equation}


\subsubsection{Adamic-Adar coefficient (AA)}

AA \cite{adamic2003friends} is a popular measure designed to capture the notion that connections to common neighbors with fewer links are more informative and indicative of similarity between nodes in a network. The formula in Equation \ref{eq:aa} assigns weights inversely proportional to the logarithm of the number of neighbors, reducing sensitivity to highly connected nodes.\ignore{AA highlights that links to less common neighbors provide more discriminative information about node similarity.}

\begin{equation}
\label{eq:aa}
  AA(a, c) = \sum_{b\ \in\ \Gamma_a \cup \Gamma_c} \frac{1}{\log{|\Gamma_b|}}
\end{equation}


\subsubsection{Resource Allocation (RA)}

The RA metric \cite{zhou2010solving} is based on the concept of heat diffusion in a network, emphasizing that heavily connected nodes may not play a critical role in facilitating resource flow between other nodes. Unlike AA, RA penalizes high-degree common neighbors more heavily. The score between nodes $a$ and $c$ is determined by Equation \ref{eq:ra}.

\begin{equation}
\label{eq:ra}
  RA(a, c) = \sum_{b\ \in\ \Gamma_a \cup \Gamma_c} \frac{1}{|\Gamma_b|}
\end{equation}

Note that the CN, AA, and RA metrics lack normalization, and thus only convey ranking information \cite{wang2014link}. In practical applications, one should choose the right metric based on the network's characteristics --- there is no universally dominating metric \cite{zhou2021progresses, ghasemian2020stacking, wang2014link, liben2003link}.
%% NOTE; What is the complexity of each similarity metric. Mention at the end of all in preliminaries.




\subsection{Measuring Prediction Quality}

A number of measures are used to assess link prediction performance. These include precision, recall, F1 score, and Area Under the Receiver Curve (AUC) \cite{arrar2023comprehensive}. However, AUC is insufficient for early quality assessment, as it may inaccurately favor algorithms ranking many negatives at the bottom \cite{zhou2021progresses, yang2015evaluating, lichtnwalter2012link}. Accordingly, we focus on precision, recall, and F1 score in this report \cite{lu2015toward}.


\subsubsection{Precision}

Precision measures the ratio of correctly predicted links $P^\checkmark$ to all predicted links $P = P^\checkmark \cup P^\times$, where $P^\times$ is the set of incorrectly predicted links \cite{arrar2023comprehensive, zhou2021progresses}. Equation \ref{eq:precision} provides the formula for precision computation.

\begin{equation}
\label{eq:precision}
  \text{Precision} = \frac{|P^\checkmark|}{|P|}
\end{equation}


\subsubsection{Recall}

Unlike precision, recall measures the ratio of correctly predicted links $P^\checkmark$ to the new ground-truth links $E^U$, as presented in Equation \ref{eq:recall} \cite{arrar2023comprehensive, zhou2021progresses}. If the number of predicted links is equal to the number of new ground-truth links, then recall is the same as precision \cite{zhou2021progresses, lu2011link, liben2003link}.

\begin{equation}
\label{eq:recall}
  \text{Recall} = \frac{|P^\checkmark|}{|E^U|}
\end{equation}


\subsubsection{F1 score}

F1 score is a measure of the balance between precision and recall \cite{arrar2023comprehensive}. It is calculated as the harmonic mean of precision and recall, as shown in Equation \ref{eq:f1score}.

\begin{equation}
\label{eq:f1score}
  \text{F1 score} = 2 * \frac{\text{Precision} * \text{Recall}}{\text{Precision} + \text{Recall}}
\end{equation}

A majority of link prediction studies apply random division of the ground-truth edges $E$, into sets of observed $E^O$ and unobserved edges $E^U$ to assess link prediction performance \cite{zhou2021progresses}. The number of unobserved edges $|E^U|$ is commonly set at $10\%$ of total links in $E$, based on empirical findings that it yields statistically solid results without significantly altering the network's structure \cite{lu2015toward}.




\subsection{Baseline Approach for Neighborhood-based Link Prediction}

A baseline approach for neighborhood-based link prediction involves computing similarity scores between all non-connected node pairs $\{(a, c)\ |\ a, c \in V; (a, c) \notin E\}$, and returning the node pairs with top-$k$ scores as the predicted links. The similarity score is computed by assessing the commonality of neighbors between the two nodes. This approach is used by an number of studies previously mentioned \cite{gatadi2023lpcd, saifi2023fast, benhidour2022approach, mumin2022efficient, rafiee2020cndp, guo2019node, yang2015new, papadimitriou2012fast, wang2019link}. Notably, popular network analysis software packages such as NetworKit \cite{staudt2016networkit} and igraph \cite{csardi2006igraph} also implement this baseline approach.

While this approach is simple to understand, it has severe computational costs. Finding the common neighbors $\Gamma_a \cap \Gamma_c$ of node pairs $(a, c)$ using a naive method has a time complexity of $O(D^2)$, where $D$ is the degree of the maximum degree node in the graph. This results in an overall time complexity of $O(N^2D^2)$. Using a hashtable, one can only reduce the time complexity to $O(N^2D)$. Additionally, this method involves significant unnecessary computations, as many node pairs are likely to lack common neighbors.
