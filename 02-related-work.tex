Link prediction in network analysis encompasses various algorithms, such as similarity-based methods, dimensionality reduction, and machine learning \cite{arrar2023comprehensive}. The use of similarity measures for link prediction is based on the intuition that individuals tend to form connections with others who share similar characteristics \cite{wang2014link}. Similarity measures are broadly categorized into three types: local, quasi-local, and global. Local measures are based on the neighborhood information of nodes within a path distance of two, global measures consider information from the entire network for nodes, and quasi-local measures blend both approaches. Other similarity-based approaches involve random walks and communities \cite{arrar2023comprehensive}.

Dimensionality reduction techniques \cite{coskun2015link} attempt to map the network's information into a lower dimensional space, while preserving its structural information. These include embedding-based and matrix factorization based methods. On the other hand, machine learning techniques utilize extracted features from the network data to predict the probability of a link forming between two nodes based on these features. These include the use of supervised, unsupervised, reinforcement, and deep learning \cite{cui2018survey, arrar2023comprehensive}.

While effective in capturing nonlinear relationships for accurate predictions in complex networks, embedding-based methods face challenges with high-centrality nodes. Matrix factorization methods often struggle with complex network structures, require substantial computational resources and pose overfitting risks \cite{arrar2023comprehensive, martinez2016survey}. Machine learning based approaches have their own set of drawbacks. These include the need for obtaining large labeled datasets, high-quality features, and domain expertise in supervised learning. Deep learning, while not requiring feature extraction, still demands a substantial amount of labeled data and raises concerns about interpretability and overfitting \cite{cui2018survey}.

Similarity-based link prediction methods continue to stay relevant, despite their usually lower prediction accuracy. This is because the size of graphs originated from the web, social networks or biological relations force us to use very simple algorithms if those graphs are to be computed in acceptable time \cite{garcia2014link}. Similarity-based link prediction methods are highly cost-effective, as they offer competitive prediction quality with their low complexity in time and space \cite{zhou2021progresses}. Further, in certain applications like friend recommendation, preference is given to predictions with explanations, a feature not readily achievable through machine learning techniques \cite{barbieri2014follow}.

%% ON COMMON NEIGHBORS
Yang et al. \cite{yang2015new} introduce the Local Neighbors Link (LNL) measure, motivated by cohesion between common neighbors and predicted nodes, and implemented it on both MapReduce and Spark. Cui et al. \cite{cui2016bounded} present a parallel algorithm for efficiently evaluating Common Neighbors (CN) similarity, obtaining node pairs with CN values surpassing a specified lower bound. Guo et al. \cite{guo2019node} propose Common Neighbour Tightness (CNT), incorporating the aggregation degree of common neighbors by considering their proximity through local information and neighborhood tightness. Rafiee et al. \cite{rafiee2020cndp} introduce Common Neighbors Degree Penalization (CNDP), which factors in clustering coefficient as a structural property and considers neighbors of shared neighbors. Mumin et al. \cite{mumin2022efficient} contribute an algorithm combining common neighbors and node degree distribution to estimate link presence likelihood between two nodes based on local information.

%% ON RANDOM WALK, DIFFUSION
Papadimitriou et al. \cite{papadimitriou2012fast} introduce a similarity-based algorithm employing traversals on paths of limited length, grounded in the small world hypothesis. Their approach extends to directed and signed graphs, with discussions on a potential MapReduce implementation. Kalkan and Hambiralovic \cite{kalkanfinding} propose link prediction based on Personalized PageRank. Vega-Oliveros et al. \cite{vega2021link} investigate the use of susceptible-infected-recovered and independent cascade diffusion models. Their progressive-diffusion (PD) method, founded on nodes' propagation dynamics, provides a stochastic discrete-time rumor model for link prediction.

%% ON COMMUNITY
Mohan et al. \cite{mohan2017scalable} introduce a hybrid similarity measure utilizing parallel label propagation for community detection and a parallel community information-based Adamic-Adar measure, employing the Bulk Synchronous Parallel (BSP) programming model. Wang et al. \cite{wang2019link} propose a link prediction algorithm incorporating an adjustable parameter based on community information (CI), applying it to various similarity indices and a family of CI-based indices. They also develop a parallel algorithm for large-scale complex networks using Spark GraphX. Bastami et al. \cite{bastami2019gravitation} present a gravitation-based link prediction approach, enhancing local and global predictions through the integration of node features, community information, and graph properties. Saifi et al. \cite{saifi2023fast} propose an approach that accelerates link prediction using local and path-based similarity measures by operating on the connected components of a network rather than the entire network.

%% ON APPROXIMATION
Shin et al. \cite{shin2012multi} introduce Multi-Scale Link Prediction (MSLP), employing a tree-structured approximation algorithm for efficient link prediction in large networks. Garcia-Gasulla and Cort{\'e}s \cite{garcia2014link} propose a local link prediction algorithm based on an underlying hierarchical model, emphasizing aspects of parallelization, approximation, and data locality for computational efficiency. Ferreira et al. \cite{ferreira2019scalability} present a multilevel optimization to enhance the scalability of any link prediction algorithm by reducing the original network to a coarsened version. Benhidour et al. \cite{benhidour2022approach} propose a link prediction method for directed networks, leveraging the similarity-popularity paradigm. The algorithms approximate hidden similarities as shortest path distances, using edge weights that capture and factor out links' asymmetry and nodes' popularity.

%% ON BIPARTITE
\ignore{Aslan and Kaya \cite{aslan2018topic} introduce a similarity-based method using weighted projection to predict potential links between authors and topics in a large-scale bipartite academic information network. Sarhangnia et al. \cite{sarhangnia2022novel} present a similarity measure for link prediction in bipartite social networks, focusing on the neighborhood structure. Shifting to multiplex networks, Sharma and Singh \cite{sharma2016efficient} propose an algorithm for weight prediction using link similarity measures, contributing to the efficient analysis of multiplex network structures. ORCS.}

As mentioned earlier, similarity-based algorithms are competitive to other high-quality dimensionality reduction and machine learning techniques, thanks to their simplicity, interpretability \cite{pai2019netdx, barbieri2014follow}, and computational efficiency \cite{garcia2014link} --- and are thus often combined with other techniques \cite{kumari2022supervised, abuoda2020link, pai2019netdx}. However, the evaluation of these algorithms on large networks is crucial, as testing on small networks can yield misleading conclusions \cite{zhou2021progresses, zhou2021experimental}. Despite this, a significant portion of the discussed works focuses on small \cite{guo2019node, rafiee2020cndp, mumin2022efficient, papadimitriou2012fast, vega2021link, saifi2023fast, ferreira2019scalability, benhidour2022approach} to medium-scale graphs \cite{yang2015new, cui2016bounded, kalkanfinding, mohan2017scalable, wang2019link, bastami2019gravitation, shin2012multi, garcia2014link}, with less than a million or billion edges. Parallelism becomes essential on large networks, and while some approaches, such as the ones based on common neighbors \cite{yang2015new, cui2016bounded}, random walks \cite{papadimitriou2012fast}, community structures \cite{mohan2017scalable, wang2019link}, and approximation \cite{garcia2014link}, incorporate parallelism, the design of suitable data structures for efficient score computation remains an often-overlooked aspect. This technical report aims to bridge both gaps, while also proposing a heuristic for efficient computation.
